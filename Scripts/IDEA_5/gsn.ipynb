{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GSN: Generative Symbiotic Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/animesh/Programming/Envs/deep_learning/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "# packages used for machine learning\n",
    "import tensorflow as tf\n",
    "\n",
    "# packages used for processing: \n",
    "import matplotlib.pyplot as plt # for visualization\n",
    "import numpy as np\n",
    "\n",
    "# for operating system related stuff\n",
    "import os\n",
    "import sys # for memory usage of objects\n",
    "from subprocess import check_output\n",
    "\n",
    "# import scipy image resize module\n",
    "from scipy.misc import imresize\n",
    "\n",
    "# to plot the images inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data files are available in the \"../Data/\" directory.\n",
    "\n",
    "def exec_command(cmd):\n",
    "    '''\n",
    "        function to execute a shell command and see it's \n",
    "        output in the python console\n",
    "        @params\n",
    "        cmd = the command to be executed along with the arguments\n",
    "              ex: ['ls', '../input']\n",
    "    '''\n",
    "    print(check_output(cmd).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "Error_analysis\n",
      "LICENSE\n",
      "Literature_survey\n",
      "Models\n",
      "README.md\n",
      "Res\n",
      "Scripts\n",
      "Writeup_for_publication\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the structure of the project directory\n",
    "exec_command(['ls', '../..'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Set the constants for the script '''\n",
    "\n",
    "# various paths of the files\n",
    "idea = \"IDEA_5\"\n",
    "base_path = '.'\n",
    "base_model_path = './Models'\n",
    "graph_viz_path = \"./graph_viz\"\n",
    "\n",
    "# constant values:\n",
    "num_classes = 10\n",
    "seed_value = 3\n",
    "ndf = 64; ngf = ndf\n",
    "class_lr = 2e-4\n",
    "gen_lr = 2e-4\n",
    "\n",
    "summary_checkpoint = 3\n",
    "\n",
    "batch_size = 32\n",
    "loss_threshold = 1e-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed_value)\n",
    "tf.set_random_seed(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph_viz\n",
      "gsn.ipynb\n",
      "Models\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the contents inside the data folder\n",
    "exec_command(['ls', base_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "# range normalize the data:\n",
    "x_train = x_train / 255; x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_data shapes: (50000, 32, 32, 3) (10000, 32, 32, 3)\n",
      "Test_data shapes: (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# print the shape information of the collected data\n",
    "print(\"Training_data shapes:\", x_train.shape, x_test.shape)\n",
    "print(\"Test_data shapes:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resize all the images to 64 x 64 size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\" Run the cell again to see different output\"\"\"\n",
    "# show a random image:\n",
    "random_image_number = np.random.randint(len(x_train))\n",
    "random_image = x_train[random_image_number]\n",
    "label = y_train[random_image_number]\n",
    "plt.figure().suptitle(\"Class: \"+str(label[0]))\n",
    "plt.imshow(random_image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print a small slice of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01960784 0.01960784 0.01568627 0.01568627 0.01960784]\n",
      " [0.01568627 0.01568627 0.01176471 0.01568627 0.01176471]\n",
      " [0.00392157 0.02745098 0.03137255 0.03529412 0.06666667]\n",
      " [0.14901961 0.26666667 0.28627451 0.29019608 0.23921569]\n",
      " [0.34901961 0.42745098 0.44313725 0.43137255 0.3372549 ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[33, :5, :5, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "randomly shuffle the test dataset to separate out a small fraction (2000 images) for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to perform synchronous random shuffling of the training data\n",
    "def synch_random_shuffle_non_np(X, Y):\n",
    "    '''\n",
    "        ** This function takes in the parameters that are non numpy compliant dtypes such as list, tuple, etc.\n",
    "        Although this function works on numpy arrays as well, this is not as performant enough\n",
    "        @param\n",
    "        X, Y => The data to be shuffled\n",
    "        @return => The shuffled data\n",
    "    '''\n",
    "    combined = list(zip(X, Y))\n",
    "\n",
    "    # shuffle the combined list in place\n",
    "    np.random.shuffle(combined)\n",
    "\n",
    "    # extract the data back from the combined list\n",
    "    X[:], Y[:] = zip(*combined)\n",
    "\n",
    "    # return the shuffled data:\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = synch_random_shuffle_non_np(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test_data shapes: (10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# ensure the shapes are intact \n",
    "print(\"Test_data shapes:\", x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to split the data into train - dev sets:\n",
    "def split_train_dev(X, Y, train_percentage):\n",
    "    '''\n",
    "        function to split the given data into two small datasets (train - dev)\n",
    "        @param\n",
    "        X, Y => the data to be split\n",
    "        (** Make sure the train dimension is the first one)\n",
    "        train_percentage => the percentage which should be in the training set.\n",
    "        (**this should be in 100% not decimal)\n",
    "        @return => train_X, train_Y, test_X, test_Y\n",
    "    '''\n",
    "    m_examples = len(X)\n",
    "    assert train_percentage < 100, \"Train percentage cannot be greater than 100! NOOB!\"\n",
    "    partition_point = int((m_examples * (float(train_percentage) / 100)) + 0.5) # 0.5 is added for rounding\n",
    "\n",
    "    # construct the train_X, train_Y, test_X, test_Y sets:\n",
    "    train_X = X[: partition_point]; train_Y = Y[: partition_point]\n",
    "    test_X  = X[partition_point: ]; test_Y  = Y[partition_point: ]\n",
    "\n",
    "    assert len(train_X) + len(test_X) == m_examples, \"Something wrong in X splitting\"\n",
    "    assert len(train_Y) + len(test_Y) == m_examples, \"Something wrong in Y splitting\"\n",
    "\n",
    "    # return the constructed sets\n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test, x_valid, y_valid = split_train_dev(x_test, y_test, train_percentage=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test (training) data shapes: (8000, 32, 32, 3) (8000, 1)\n",
      "Validation data shapes: (2000, 32, 32, 3) (2000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"Test (training) data shapes:\", x_test.shape, y_test.shape)\n",
    "print(\"Validation data shapes:\", x_valid.shape, y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! it is quite good till now..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's define the network now ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The classifier network:\n",
    "def classifier_network(x, batch_norm_mode, variable_reuse=False):\n",
    "    \"\"\" define the network computations pipeline for the input.\n",
    "        @args\n",
    "            x: input to the network computations\n",
    "            batch_norm_mode: tensor for notifying the batch_norm mode\n",
    "        @return\n",
    "            None\n",
    "            (adds the ops to the current graph in scope)\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.variable_scope(\"Classifier_Network\", reuse=variable_reuse):\n",
    "        # block 1\n",
    "        x = tf.layers.conv2d(x, filters=ndf, kernel_size=4, strides=2, padding=\"same\", use_bias=False,\n",
    "                            name=\"conv_1\")\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.2)\n",
    "\n",
    "        # block 2\n",
    "        x = tf.layers.conv2d(x, filters=ndf*2, kernel_size=4, strides=2, padding=\"same\", use_bias=False,\n",
    "                            name=\"conv_2\")\n",
    "        x = tf.layers.batch_normalization(x, training=batch_norm_mode,\n",
    "                                         name=\"bn_1\")\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.2)\n",
    "\n",
    "        # block 3\n",
    "        x = tf.layers.conv2d(x, filters=ndf*4, kernel_size=4, strides=2, padding=\"same\", use_bias=False,\n",
    "                            name=\"conv_3\")\n",
    "        x = tf.layers.batch_normalization(x, training=batch_norm_mode,\n",
    "                                         name=\"bn_2\")\n",
    "        x = tf.nn.leaky_relu(x, alpha=0.2)\n",
    "\n",
    "        # final block\n",
    "        x = tf.layers.conv2d(x, filters=ndf*8, kernel_size=4, strides=1, padding=\"valid\", use_bias=False,\n",
    "                            name=\"conv_4\")\n",
    "        x = tf.squeeze(x, axis=(1, 2))\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the inputs to the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Inputs\"):\n",
    "    x_input = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name=\"input_x\")    \n",
    "    tf.summary.image(\"Input_Images\", x_input)    \n",
    "    bn_train_mode = tf.placeholder(tf.bool, shape=(), name=\"batch_norm_mode\")\n",
    "    y_label = tf.placeholder(tf.int32, shape=(None, 1), name=\"input_labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the one hot encoder for the input labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded_Labels:  (?, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"One_Hot_Encoder\"):\n",
    "    y_encoded = tf.one_hot(y_label, depth=num_classes, name=\"one_hot_encode\")\n",
    "    \n",
    "print(\"Encoded_Labels: \", y_encoded.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the classifer output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier_Network_Output_shape:  (?, 512)\n"
     ]
    }
   ],
   "source": [
    "clas_op = classifier_network(x_input, bn_train_mode)\n",
    "print(\"Classifier_Network_Output_shape: \", clas_op.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier_Network/conv_1/kernel:0 (4, 4, 3, 64)\n",
      "Classifier_Network/conv_2/kernel:0 (4, 4, 64, 128)\n",
      "Classifier_Network/bn_1/gamma:0 (128,)\n",
      "Classifier_Network/bn_1/beta:0 (128,)\n",
      "Classifier_Network/conv_3/kernel:0 (4, 4, 128, 256)\n",
      "Classifier_Network/bn_2/gamma:0 (256,)\n",
      "Classifier_Network/bn_2/beta:0 (256,)\n",
      "Classifier_Network/conv_4/kernel:0 (4, 4, 256, 512)\n"
     ]
    }
   ],
   "source": [
    "classifier_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"Classifier_Network\")\n",
    "for var in classifier_variables:\n",
    "    tf.summary.histogram(var.name.split(':')[0], var)\n",
    "    print(var.name, var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier connection dense layer:\n",
    "def dense_classifier(x, variable_reuse=False):\n",
    "    with tf.variable_scope(\"Dense_Classifier\", reuse=variable_reuse):\n",
    "        raw_preds = tf.layers.dense(x, activation=tf.nn.relu,\n",
    "                                    units=num_classes, name=\"final_classification_layer\")\n",
    "\n",
    "        predictions = tf.nn.softmax(raw_preds)\n",
    "    \n",
    "    return raw_preds, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_preds, predictions = dense_classifier(clas_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense_Classifier/final_classification_layer/kernel:0 (512, 10)\n",
      "Dense_Classifier/final_classification_layer/bias:0 (10,)\n"
     ]
    }
   ],
   "source": [
    "fdc_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"Dense_Classifier\")\n",
    "for var in fdc_variables:\n",
    "    tf.summary.histogram(var.name.split(':')[0], var)\n",
    "    print(var.name, var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The generator network\n",
    "def generator_network(x, batch_norm_mode):\n",
    "    \"\"\" define the network computations pipeline for the input.\n",
    "        @args\n",
    "            x: input to the network computations\n",
    "            batch_norm_mode: tensor for notifying the batch_norm mode\n",
    "        @return\n",
    "            None\n",
    "            (adds the ops to the current graph in scope)\n",
    "    \"\"\"\n",
    "\n",
    "    with tf.variable_scope(\"Generator_Network\"):\n",
    "        # block 1\n",
    "        x = tf.layers.conv2d_transpose(x, filters=ndf*4, kernel_size=4, strides=2, padding=\"valid\", use_bias=False,\n",
    "                            name=\"conv_1_transpose\")\n",
    "        x = tf.layers.batch_normalization(x, training=batch_norm_mode, name=\"bn_1\")\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        # block 2\n",
    "        x = tf.layers.conv2d_transpose(x, filters=ndf*2, kernel_size=4, strides=2, padding=\"same\", use_bias=False,\n",
    "                            name=\"conv_2_transpose\")\n",
    "        x = tf.layers.batch_normalization(x, training=batch_norm_mode, name=\"bn_2\")\n",
    "        x = tf.nn.relu(x)\n",
    "        \n",
    "        # block 3\n",
    "        x = tf.layers.conv2d_transpose(x, filters=ndf, kernel_size=4, strides=2, padding=\"same\", use_bias=False,\n",
    "                            name=\"conv_3_transpose\")\n",
    "        x = tf.layers.batch_normalization(x, training=batch_norm_mode, name=\"bn_3\")\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        # final block \n",
    "        x = tf.layers.conv2d_transpose(x, filters=3, kernel_size=4, strides=2, padding=\"same\", use_bias=False,\n",
    "                            name=\"conv_4_transpose\")\n",
    "        x = tf.nn.sigmoid(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Pipe\"):\n",
    "    bt_size = tf.shape(clas_op)[0]\n",
    "    noise = tf.random_normal(shape=(bt_size, 128), name=\"random_noise\")\n",
    "    generator_in = tf.concat([clas_op, noise], axis=-1, name=\"conditional_output_with_noise\")\n",
    "    generator_in = tf.expand_dims(tf.expand_dims(generator_in, axis=1, name=\"expand_dim_1\"), \n",
    "                                  axis=1, name=\"expand_dim_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator_Network_input_shape: Tensor(\"Pipe/expand_dim_2:0\", shape=(?, 1, 1, 640), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"Generator_Network_input_shape:\", generator_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator_Network_output_shape: (?, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "generator_out = generator_network(generator_in, bn_train_mode)\n",
    "tf.summary.image(\"Generated_Images\", generator_out)\n",
    "print(\"Generator_Network_output_shape:\", generator_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator_Network/conv_1_transpose/kernel:0 (4, 4, 256, 640)\n",
      "Generator_Network/bn_1/gamma:0 (256,)\n",
      "Generator_Network/bn_1/beta:0 (256,)\n",
      "Generator_Network/conv_2_transpose/kernel:0 (4, 4, 128, 256)\n",
      "Generator_Network/bn_2/gamma:0 (128,)\n",
      "Generator_Network/bn_2/beta:0 (128,)\n",
      "Generator_Network/conv_3_transpose/kernel:0 (4, 4, 64, 128)\n",
      "Generator_Network/bn_3/gamma:0 (64,)\n",
      "Generator_Network/bn_3/beta:0 (64,)\n",
      "Generator_Network/conv_4_transpose/kernel:0 (4, 4, 3, 64)\n"
     ]
    }
   ],
   "source": [
    "generator_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=\"Generator_Network\")\n",
    "for var in generator_variables:\n",
    "    tf.summary.histogram(var.name.split(':')[0], var)\n",
    "    print(var.name, var.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions_output: (?, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Predictions_output:\", predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Losses\"):\n",
    "    with tf.name_scope(\"classifier_loss\"):\n",
    "        class_loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(logits=raw_preds, labels=y_encoded))\n",
    "    \n",
    "        tf.summary.scalar(\"classifier_loss\", class_loss)\n",
    "    \n",
    "    with tf.name_scope(\"generator_loss\"):\n",
    "        gen_loss = tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "            logits=dense_classifier(\n",
    "                        classifier_network(generator_out, bn_train_mode, variable_reuse=True),\n",
    "                        variable_reuse=True\n",
    "                   )[0],\n",
    "            labels=y_encoded))\n",
    "        \n",
    "        tf.summary.scalar(\"generator_loss\", gen_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Accuracy\"):\n",
    "    correct_vals = tf.cast(tf.equal(tf.argmax(predictions, axis=-1, output_type=tf.int32), y_label), tf.float32)\n",
    "    accuracy = tf.reduce_mean(correct_vals, name=\"accuracy\")\n",
    "    tf.summary.scalar(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Optimizers\"):\n",
    "    with tf.name_scope(\"classifier_optimizer\"):\n",
    "        classifier_optimizer = tf.train.AdamOptimizer(learning_rate=class_lr).minimize(class_loss, \n",
    "                                                    var_list=classifier_variables + fdc_variables, name=\"clas_op\")\n",
    "    \n",
    "    with tf.name_scope(\"generator_optimizer\"):\n",
    "        generator_optimizer = tf.train.AdamOptimizer(learning_rate=gen_lr).minimize(gen_loss,\n",
    "                                                    var_list=generator_variables, name=\"gen_op\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Errands\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    all_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before starting the training, check the graph in Tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "run the following cell. This generates an events file in the `./graphviz/` directory. Run tensorboard inside that directory to visualize the graph structure prior to running the training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the graph to check the structure\n",
    "tensorboard_writer = tf.summary.FileWriter(logdir=graph_viz_path, \n",
    "                                           graph=tf.get_default_graph(), filename_suffix=\".bot\")\n",
    "\n",
    "# delete this writer. I will create another one while training the network\n",
    "del tensorboard_writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, I can run the training of the network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Model_2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model save path:  ./Models/Model_2\n"
     ]
    }
   ],
   "source": [
    "model_save_path = os.path.join(base_model_path, model_name)\n",
    "print(\"Model save path: \", model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training exaples: 8000\n"
     ]
    }
   ],
   "source": [
    "total_train_samples = len(x_test)\n",
    "print(\"total training exaples:\", total_train_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Training cell for the network \"\"\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # create a tensorboard writer\n",
    "    tensorboard_writer = tf.summary.FileWriter(logdir=model_save_path, graph=sess.graph, filename_suffix=\".bot\")\n",
    "    \n",
    "    # create a saver\n",
    "    saver = tf.train.Saver(max_to_keep=2)\n",
    "    \n",
    "    # restore the session if the checkpoint exists:\n",
    "    if(os.path.isfile(os.path.join(model_save_path, \"checkpoint\"))):\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(model_save_path))\n",
    "    \n",
    "    else: # initialize all the variables:\n",
    "        sess.run(init)\n",
    "        \n",
    "    loss_delta = float('inf'); prev_loss = 0\n",
    "    \n",
    "    global_step = 0\n",
    "    epoch = 0\n",
    "    # start the training loop ... \n",
    "    while loss_delta >= loss_threshold:\n",
    "        # run the training\n",
    "        no_of_batches = int(np.ceil(total_train_samples / batch_size))\n",
    "        gen_x, gen_y = None, None # start with empty lists\n",
    "        \n",
    "        cls_loss = []; cls_accuracy = []\n",
    "        gen_loss = [];\n",
    "        \n",
    "        for bat_no in range(no_of_batches):\n",
    "            # extract the data for training\n",
    "            start = bat_no * batch_size; end = start + batch_size\n",
    "            \n",
    "            batch_x = x_test[start: end]; batch_y = y_test[start: end]\n",
    "            \n",
    "            # append the generated data\n",
    "            if gen_x is not None and gen_y is not None:\n",
    "                app_batch_x = np.concatenate([batch_x, gen_x], axis=0)\n",
    "                app_batch_y = np.concatenate([batch_y, gen_y], axis=0)\n",
    "            else:\n",
    "                app_batch_x = batch_x\n",
    "                app_batch_y = batch_y\n",
    "        \n",
    "            #==================================================================\n",
    "            # Classifier training\n",
    "            #==================================================================\n",
    "            # run the classification training step\n",
    "            _, cls_ls, cls_acc = sess.run([classifier_optimizer, class_loss, accuracy],\n",
    "                                      feed_dict={\n",
    "                                          x_input: app_batch_x,\n",
    "                                          y_label: app_batch_y,\n",
    "                                          bn_train_mode: True\n",
    "                                      })\n",
    "            \n",
    "            #==================================================================\n",
    "            # Generator training\n",
    "            #==================================================================\n",
    "            # run the generator training step\n",
    "            _, gen_ls, gen_imgs = sess.run([generator_optimizer, \n",
    "                                                           gen_loss, generator_out],\n",
    "                                                      feed_dict={\n",
    "                                                          x_input: batch_x,\n",
    "                                                          y_label: batch_y,\n",
    "                                                          bn_train_mode: True\n",
    "                                                      })\n",
    "            \n",
    "            # fill the gen_x and gen_y batches:\n",
    "            idx = np.random.randint(batch_size, size=int(batch_size / 2))\n",
    "            gen_x = gen_imgs[idx]; gen_y = batch_y[idx]\n",
    "            \n",
    "            cls_loss.append(cls_ls); cls_accuracy.append(cls_acc)\n",
    "            gen_loss.append(gen_ls)\n",
    "        \n",
    "            if bat_no == 0 or (bat_no + 1) % summary_checkpoint == 0:\n",
    "                # this includes all the summaries\n",
    "                sums = sess.run(all_summaries, feed_dict={\n",
    "                                                    x_input: batch_x,\n",
    "                                                    y_label: batch_y,\n",
    "                                                    bn_train_mode: True\n",
    "                                                })\n",
    "                tensorboard_writer.add_summary(sums, global_step=global_step)\n",
    "                \n",
    "            global_step += 1\n",
    "        \n",
    "        current_loss = np.mean(cls_loss)\n",
    "        loss_delta = np.abs(current_loss - prev_loss)\n",
    "        prev_loss = current_loss\n",
    "        \n",
    "        # print all the summary\n",
    "        print(\"Classification_Loss: %.3f Classification_Accuracy: %.3f\" %(current_loss, np.mean(cls_accuracy)))\n",
    "        print(\"Generation_Loss: %.3f\" %(np.mean(gen_loss)))\n",
    "        \n",
    "        epoch += 1\n",
    "        \n",
    "        if epoch == 1 or epoch % summary_checkpoint == 0:\n",
    "            graph_save_status = (epoch == 1)\n",
    "            saver.save(sess, save_path=os.path.join(model_save_path, model_name), \n",
    "                       global_step=epoch, write_meta_graph=graph_save_status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assess the results now ...."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
