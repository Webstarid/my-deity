{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, I use the update rules according to the last notebook (based on the Newton-Raphson method) on the MNIST dataset.\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# This notebook also generates the comparison summary against the prevailing first order (not using hessian) optimization techniques.\n",
    "\n",
    "-------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "## Technology used: TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "start with the usual cells. I don't remember how I attained this habit. Anyway, let's get started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import all the required packages: \n",
    "# packages used for processing: \n",
    "from __future__ import print_function # making backward compatible\n",
    "\n",
    "import matplotlib.pyplot as plt # for visualization\n",
    "import numpy as np\n",
    "\n",
    "# THE TensorFlow framework\n",
    "import tensorflow as tf\n",
    "# use the tensorflow's archived version of the MNIST dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# import tensorflow debugger:\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "# for operating system related stuff\n",
    "import os\n",
    "import sys # for memory usage of objects\n",
    "from subprocess import check_output\n",
    "\n",
    "# to plot the images inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input data files are available in the \"../Data/\" directory.\n",
    "\n",
    "def exec_command(cmd):\n",
    "    '''\n",
    "        function to execute a shell command and see it's \n",
    "        output in the python console\n",
    "        @params\n",
    "        cmd = the command to be executed along with the arguments\n",
    "              ex: ['ls', '../input']\n",
    "    '''\n",
    "    print(check_output(cmd).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "Error_analysis\n",
      "LICENSE\n",
      "Literature_survey\n",
      "Models\n",
      "README.md\n",
      "Res\n",
      "Scripts\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the structure of the project directory\n",
    "exec_command(['ls', '../..'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set a seed value for the script\n",
    "seed_value = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed_value) # set this seed for a device independant consistent behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "''' Set the constants for the script '''\n",
    "\n",
    "# various paths of the files\n",
    "base_data_path = \"../../Data\" # the data path\n",
    "\n",
    "base_model_path = \"../../Models/IDEA_2\"\n",
    "\n",
    "# constant values for the script\n",
    "num_digits = 10 # This is defined. There are 10 labels for 10 digits\n",
    "img_dim = 28 # images are 28 x 28 sized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper parameters for tweaking.\n",
    "# =================================================================================================================\n",
    "training_batch_size = 64 # 64 images in each batch\n",
    "no_of_epochs = 12\n",
    "\n",
    "\n",
    "# network architecture related parameters:\n",
    "''' Note that the number of layers will be fixed. you can tweak the number of hidden neurons in these layers: '''\n",
    "num_hidden_lay_1 = 512\n",
    "num_hidden_lay_2 = 512\n",
    "num_hidden_lay_3 = num_digits\n",
    "\n",
    "# learning rate required for other optimizers:\n",
    "learning_rate = 3e-4 # lolz! the karpathy constant\n",
    "# ================================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../Data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../Data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../Data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../Data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(os.path.join(base_data_path, \"MNIST_data\"), seed=seed_value, one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X = mnist.train.images; train_Y = mnist.train.labels\n",
    "dev_X = mnist.validation.images; dev_Y = mnist.validation.labels\n",
    "test_X = mnist.test.images; test_Y = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data shapes:  (55000, 784) (55000, 10)\n",
      "Development Data shapes:  (5000, 784) (5000, 10)\n",
      "Test Data shapes:  (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# print all the shapes:\n",
    "print(\"Training Data shapes: \", train_X.shape, train_Y.shape)\n",
    "print(\"Development Data shapes: \", dev_X.shape, dev_Y.shape)\n",
    "print(\"Test Data shapes: \", test_X.shape, test_Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the total_train_examples, total_dev_examples and the total_test_examples using the above arrays\n",
    "total_train_examples = train_X.shape[0]\n",
    "total_dev_examples = dev_X.shape[0]\n",
    "total_test_examples = test_X.shape[0]\n",
    "input_dimension = train_X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_data_size = 55000\n",
      "Development_data_size = 5000\n",
      "Test_data_size = 10000\n",
      "Input data dimensions = 784\n"
     ]
    }
   ],
   "source": [
    "# just double checking if all the values are correct:\n",
    "print(\"Training_data_size =\", total_train_examples)\n",
    "print(\"Development_data_size =\", total_dev_examples)\n",
    "print(\"Test_data_size =\", total_test_examples)\n",
    "print(\"Input data dimensions =\", input_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the following is a randomized cell for visualizing the input data. This is just to verify the sanity of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEVCAYAAAAvoDOaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7e401f7090>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "''' Randomized cell: Behaviour changes upon running multiple times '''\n",
    "\n",
    "random_index = np.random.randint(total_train_examples)\n",
    "\n",
    "# bring the random image from the training data\n",
    "random_image = train_X[random_index].reshape((img_dim, img_dim))\n",
    "label_for_random_image = np.argmax(train_Y[random_index])\n",
    "\n",
    "# display this random image:\n",
    "plt.figure().suptitle(\"Image for digit: \" + str(label_for_random_image))\n",
    "plt.imshow(random_image);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### seems like we have randomly landed on a mislabelled example! That's the magic of the random_seed_value = 3\n",
    "\n",
    "don't worry! There is no jumbling in the labels. Run the above cell more times and you will see that it was just that one example that is mis labelled in the original dataset itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimentation: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the neural network graph for classifying the mnist dataset. This is going to be a very simple graph. With just three fully connected layers and there is no regularization (L2 or dropouts)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "point to restart the graph building process:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1 = tf.layers.Dense(\n",
    "            units = num_hidden_lay_1,\n",
    "            activation = tf.nn.relu,\n",
    "            use_bias = True,\n",
    "            kernel_initializer = tf.contrib.layers.xavier_initializer(),\n",
    "            bias_initializer = tf.contrib.layers.xavier_initializer(),\n",
    "            name = \"fully_connected\"\n",
    "         )\n",
    "\n",
    "layer2 = tf.layers.Dense(\n",
    "            units = num_hidden_lay_2,\n",
    "            activation = tf.nn.relu,\n",
    "            use_bias = True,\n",
    "            kernel_initializer = tf.contrib.layers.xavier_initializer(),\n",
    "            bias_initializer = tf.contrib.layers.xavier_initializer(),\n",
    "            name = \"fully_connected\"\n",
    "         )\n",
    "\n",
    "layer3 = tf.layers.Dense(\n",
    "            units = num_hidden_lay_3,\n",
    "            activation = None, # note that here we apply the softmax nonlinearity for obtaining the probabilities \n",
    "            use_bias = True,\n",
    "            kernel_initializer = tf.contrib.layers.xavier_initializer(),\n",
    "            bias_initializer = tf.contrib.layers.xavier_initializer(),\n",
    "            name = \"fully_connected\"\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the input placeholders for the computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Input_Placeholders\"):\n",
    "    tf_input_images = tf.placeholder(tf.float32, shape=(None, input_dimension), name=\"input_images\")\n",
    "    tf_input_labels = tf.placeholder(tf.float32, shape=(None, num_digits), name=\"input_labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define the neural_network computations layer by layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Layer_1\"):\n",
    "    lay_1_out = layer1(tf_input_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Layer_2\"):\n",
    "    lay_2_out = layer2(lay_1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"Layer_3\"):\n",
    "    lay_3_out = layer3(lay_2_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the dimensionality of the lay_3_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Layer_3/fully_connected/BiasAdd:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lay_3_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape is as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# extract all the weights and biases from the layers for summary generation\n",
    "lay_1_kernel, lay_1_biases = layer1.weights\n",
    "lay_2_kernel, lay_2_biases = layer2.weights\n",
    "lay_3_kernel, lay_3_biases = layer3.weights\n",
    "\n",
    "# attach summary op to all the trainable weights and biases of the three layers:\n",
    "lay_1_k_sum = tf.summary.histogram(\"l1_k\", lay_1_kernel); lay_1_b_sum = tf.summary.histogram(\"l1_b\", lay_1_biases)\n",
    "lay_2_k_sum = tf.summary.histogram(\"l2_k\", lay_2_kernel); lay_2_b_sum = tf.summary.histogram(\"l2_b\", lay_2_biases)\n",
    "lay_3_k_sum = tf.summary.histogram(\"l3_k\", lay_3_kernel); lay_3_b_sum = tf.summary.histogram(\"l3_b\", lay_3_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the predictions:\n",
    "with tf.name_scope(\"Predictions\"):\n",
    "    predictions = tf.nn.softmax(lay_3_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the loss for the model\n",
    "with tf.name_scope(\"Loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=tf_input_labels, logits=lay_3_out))\n",
    "    \n",
    "    # add a scalar summary for the loss:\n",
    "    loss_summary = tf.summary.scalar(\"Loss\", loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the errands for this model:\n",
    "with tf.name_scope(\"Errands\"):\n",
    "    all_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## session and runners:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer_1/fully_connected/kernel:0\n",
      "Layer_1/fully_connected/bias:0\n",
      "Layer_2/fully_connected/kernel:0\n",
      "Layer_2/fully_connected/bias:0\n",
      "Layer_3/fully_connected/kernel:0\n",
      "Layer_3/fully_connected/bias:0\n"
     ]
    }
   ],
   "source": [
    "# define a pseudo session to generate the visualizer and for printing all the trainable variables in the model\n",
    "with tf.Session() as sess:\n",
    "    # create the tensorboard writer:\n",
    "    tensorboard_writer = tf.summary.FileWriter(os.path.join(base_model_path, \"Visualizer\"), graph=sess.graph, \n",
    "                                              filename_suffix = \".bot\")\n",
    "    \n",
    "    # init the session:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # print all the trainable variables in the graph: \n",
    "    tvars = tf.trainable_variables()\n",
    "    tvars_vals = sess.run(tvars)\n",
    "    \n",
    "    for var, val in zip(tvars, tvars_vals):\n",
    "        print(var.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run tensorboard with the Models/IDEA_2 as the logdir to view all these visualizations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the function for training the above model along with the optimizer as an argument to it:\n",
    "def train(X, Y, batch_size, no_of_epochs, optimizing_step, model_path, model_name, debug=False):\n",
    "    '''\n",
    "        Function to train the above generated graph using the optimizing step privided\n",
    "        \n",
    "        Arguments:\n",
    "        X, Y = The data to train on.\n",
    "        batch_size = size of each minibatch\n",
    "        no_of_epochs = no of epochs to train for\n",
    "        optimizing_step = the tensorflow op that optimizes the weights\n",
    "        model_path = The path where the trained model is to be saved\n",
    "        model_name = The name of the model for saving\n",
    "        debug = boolean controlling if it needs to be a debugging session\n",
    "    '''\n",
    "    \n",
    "    # This is a temporary code and not the full blown:\n",
    "    sess = tf.InteractiveSession()\n",
    "        \n",
    "    if(debug):\n",
    "        sess = tf_debug.LocalCLIDebugWrapperSession(sess)\n",
    "\n",
    "    # create a tensorboard writer\n",
    "    tensorboard_writer = tf.summary.FileWriter(logdir=model_path, \n",
    "                                               graph=sess.graph, filename_suffix=\".bot\")\n",
    "\n",
    "    # create a saver\n",
    "    saver = tf.train.Saver(max_to_keep=3)\n",
    "\n",
    "    # restore the session if the checkpoint exists:\n",
    "    if(os.path.isfile(os.path.join(model_path, \"checkpoint\"))):\n",
    "        saver.restore(sess, tf.train.latest_checkpoint(model_path))\n",
    "\n",
    "    else: # initialize all the variables:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    global_step = 0\n",
    "    print(\"Starting the training process . . .\")\n",
    "    for epoch in range(no_of_epochs):\n",
    "\n",
    "        # run through the batches of the data:\n",
    "        for batch in range(int(np.ceil(float(total_train_examples) / batch_size))):\n",
    "            start = batch * batch_size; end = start + batch_size\n",
    "\n",
    "            # extract the relevant data:\n",
    "            batch_data_X = X[start: end]\n",
    "            batch_data_Y = Y[start: end]\n",
    "\n",
    "            _, cost, sums = sess.run([optimizing_step, loss, all_summaries], \n",
    "                                                    feed_dict={tf_input_images: batch_data_X, \n",
    "                                                              tf_input_labels: batch_data_Y})\n",
    "\n",
    "            # save the summaries\n",
    "            if(batch % 50 == 0):\n",
    "                tensorboard_writer.add_summary(sums, global_step)\n",
    "\n",
    "            # increment the global step \n",
    "            global_step += 1\n",
    "\n",
    "        print(\"epoch = \", epoch, \"cost = \", cost)\n",
    "\n",
    "        # save the model after every epoch\n",
    "        saver.save(sess, os.path.join(model_path, model_name), global_step=(epoch + 1))\n",
    "\n",
    "    # Once, the training is complete:\n",
    "    print(\"Training complete . . .\")\n",
    "    \n",
    "    # close the session -> \n",
    "    sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using the Adam optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the Adam trainer for the model defined\n",
    "with tf.name_scope(\"Adam_Trainer\"):\n",
    "    train_step_adam = tf.train.AdamOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"Adam_Model\"\n",
    "model_save_path = os.path.join(base_model_path, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training process . . .\n",
      "epoch =  0 cost =  0.0238923\n",
      "epoch =  1 cost =  0.0121582\n",
      "epoch =  2 cost =  0.00975432\n",
      "epoch =  3 cost =  0.00316183\n",
      "epoch =  4 cost =  0.00104458\n",
      "epoch =  5 cost =  0.000663358\n",
      "epoch =  6 cost =  0.000234343\n",
      "epoch =  7 cost =  0.000399052\n",
      "epoch =  8 cost =  0.000117259\n",
      "epoch =  9 cost =  0.000197179\n",
      "epoch =  10 cost =  7.91406e-05\n",
      "epoch =  11 cost =  3.6454e-05\n",
      "Training complete . . .\n"
     ]
    }
   ],
   "source": [
    "train(train_X, train_Y, training_batch_size, no_of_epochs, train_step_adam, model_save_path, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using the Adadelta Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training process . . .\n",
      "epoch =  0 cost =  2.28419\n",
      "epoch =  1 cost =  2.21074\n",
      "epoch =  2 cost =  2.14024\n",
      "epoch =  3 cost =  2.07137\n",
      "epoch =  4 cost =  2.00229\n",
      "epoch =  5 cost =  1.93292\n",
      "epoch =  6 cost =  1.86265\n",
      "epoch =  7 cost =  1.79168\n",
      "epoch =  8 cost =  1.72065\n",
      "epoch =  9 cost =  1.64979\n",
      "epoch =  10 cost =  1.5789\n",
      "epoch =  11 cost =  1.50826\n",
      "Training complete . . .\n"
     ]
    }
   ],
   "source": [
    "# define the Adadelta trainer for the model defined\n",
    "with tf.name_scope(\"Adadelta_Trainer\"):\n",
    "    train_step_adadelta = tf.train.AdadeltaOptimizer().minimize(loss) # using the default learning rate\n",
    "    \n",
    "model_name = \"Adadelta_Model\"\n",
    "model_save_path = os.path.join(base_model_path, model_name)\n",
    "\n",
    "train(train_X, train_Y, training_batch_size, no_of_epochs, train_step_adadelta, model_save_path, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using the Adagrad Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training process . . .\n",
      "epoch =  0 cost =  1.8792\n",
      "epoch =  1 cost =  1.39008\n",
      "epoch =  2 cost =  1.02289\n",
      "epoch =  3 cost =  0.784186\n",
      "epoch =  4 cost =  0.628431\n",
      "epoch =  5 cost =  0.521987\n",
      "epoch =  6 cost =  0.445172\n",
      "epoch =  7 cost =  0.387286\n",
      "epoch =  8 cost =  0.342278\n",
      "epoch =  9 cost =  0.306636\n",
      "epoch =  10 cost =  0.277921\n",
      "epoch =  11 cost =  0.254449\n",
      "Training complete . . .\n"
     ]
    }
   ],
   "source": [
    "# define the Adagrad trainer for the model defined\n",
    "with tf.name_scope(\"Adagrad_Trainer\"):\n",
    "    train_step_adagrad = tf.train.AdagradOptimizer(learning_rate).minimize(loss) \n",
    "    \n",
    "model_name = \"Adagrad_Model\"\n",
    "model_save_path = os.path.join(base_model_path, model_name)\n",
    "\n",
    "train(train_X, train_Y, training_batch_size, no_of_epochs, train_step_adagrad, model_save_path, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using the GradientDescentOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training process . . .\n",
      "epoch =  0 cost =  2.09428\n",
      "epoch =  1 cost =  1.94123\n",
      "epoch =  2 cost =  1.7722\n",
      "epoch =  3 cost =  1.59662\n",
      "epoch =  4 cost =  1.42495\n",
      "epoch =  5 cost =  1.26431\n",
      "epoch =  6 cost =  1.11987\n",
      "epoch =  7 cost =  0.993336\n",
      "epoch =  8 cost =  0.885756\n",
      "epoch =  9 cost =  0.795108\n",
      "epoch =  10 cost =  0.718521\n",
      "epoch =  11 cost =  0.653813\n",
      "Training complete . . .\n"
     ]
    }
   ],
   "source": [
    "# define the GradientDescent trainer for the model defined\n",
    "with tf.name_scope(\"GradientDescent_Trainer\"):\n",
    "    train_step_gradDesc = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "model_name = \"GradientDescent_Model\"\n",
    "model_save_path = os.path.join(base_model_path, model_name)\n",
    "\n",
    "train(train_X, train_Y, training_batch_size, no_of_epochs, train_step_gradDesc, model_save_path, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using MomentumOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training process . . .\n",
      "epoch =  0 cost =  0.850098\n",
      "epoch =  1 cost =  0.387051\n",
      "epoch =  2 cost =  0.249473\n",
      "epoch =  3 cost =  0.186767\n",
      "epoch =  4 cost =  0.152059\n",
      "epoch =  5 cost =  0.13041\n",
      "epoch =  6 cost =  0.115708\n",
      "epoch =  7 cost =  0.104882\n",
      "epoch =  8 cost =  0.0965706\n",
      "epoch =  9 cost =  0.0900359\n",
      "epoch =  10 cost =  0.0847443\n",
      "epoch =  11 cost =  0.0802271\n",
      "Training complete . . .\n"
     ]
    }
   ],
   "source": [
    "# define the Momentum trainer for the model defined\n",
    "with tf.name_scope(\"Momentum_Trainer\"):\n",
    "    train_step_momentum = tf.train.MomentumOptimizer(learning_rate, momentum=0.9).minimize(loss)\n",
    "    \n",
    "model_name = \"MomentumOptimizer_Model\"\n",
    "model_save_path = os.path.join(base_model_path, model_name)\n",
    "\n",
    "train(train_X, train_Y, training_batch_size, no_of_epochs, train_step_momentum, model_save_path, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using RMSPropOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the training process . . .\n",
      "epoch =  0 cost =  0.0177101\n",
      "epoch =  1 cost =  0.00564126\n",
      "epoch =  2 cost =  0.00187299\n",
      "epoch =  3 cost =  0.000821726\n",
      "epoch =  4 cost =  0.00041412\n",
      "epoch =  5 cost =  0.000233829\n",
      "epoch =  6 cost =  0.000173776\n",
      "epoch =  7 cost =  9.69946e-05\n",
      "epoch =  8 cost =  3.88677e-05\n",
      "epoch =  9 cost =  8.10112e-06\n",
      "epoch =  10 cost =  1.12947e-05\n",
      "epoch =  11 cost =  2.38279e-05\n",
      "Training complete . . .\n"
     ]
    }
   ],
   "source": [
    "# define the Momentum trainer for the model defined\n",
    "with tf.name_scope(\"RMSProp_Trainer\"):\n",
    "    train_step_rmsprop = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "model_name = \"RMSpropOptimizer_Model\"\n",
    "model_save_path = os.path.join(base_model_path, model_name)\n",
    "\n",
    "train(train_X, train_Y, training_batch_size, no_of_epochs, train_step_rmsprop, model_save_path, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train using the RANIK_Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The op used for defining the optimizer:\n",
    "with tf.name_scope(\"ranik\"):\n",
    "    # obtain the gradients of the cost wrt all the three layers' parameters\n",
    "    with tf.name_scope(\"gradients\"):\n",
    "        gra_lay_1_kernel, gra_lay_1_biases = tf.gradients(loss, [lay_1_kernel, lay_1_biases])\n",
    "        gra_lay_2_kernel, gra_lay_2_biases = tf.gradients(loss, [lay_2_kernel, lay_2_biases])\n",
    "        gra_lay_3_kernel, gra_lay_3_biases = tf.gradients(loss, [lay_3_kernel, lay_3_biases])\n",
    "    \n",
    "    # define the ops for updating the three layers kernels and biases\n",
    "    with tf.name_scope(\"update\"):\n",
    "        op1=tf.assign(lay_1_kernel, lay_1_kernel-((loss * gra_lay_1_kernel) / (loss + tf.square(gra_lay_1_kernel))))\n",
    "        op2=tf.assign(lay_1_biases, lay_1_biases-((loss * gra_lay_1_biases) / (loss + tf.square(gra_lay_1_biases))))\n",
    "        op3=tf.assign(lay_2_kernel, lay_2_kernel-((loss * gra_lay_2_kernel) / (loss + tf.square(gra_lay_2_kernel))))\n",
    "        op4=tf.assign(lay_2_biases, lay_2_biases-((loss * gra_lay_2_biases) / (loss + tf.square(gra_lay_2_biases))))\n",
    "        op5=tf.assign(lay_3_kernel, lay_3_kernel-((loss * gra_lay_3_kernel) / (loss + tf.square(gra_lay_3_kernel))))\n",
    "        op6=tf.assign(lay_3_biases, lay_3_biases-((loss * gra_lay_3_biases) / (loss + tf.square(gra_lay_3_biases))))\n",
    "        \n",
    "        # group all the 6 ops into one\n",
    "        update_step = tf.group(op1, op2, op3, op4, op5, op6, name=\"combined_update\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "tfdbg: caught SIGINT; calling sys.exit(1).\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/animesh/Programming/platforms/anaconda3/envs/snakes/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# define the Ranik trainer for the model defined\n",
    "with tf.name_scope(\"Ranik_Trainer\"):\n",
    "    train_step_ranik = update_step\n",
    "    \n",
    "model_name = \"RanikOptimizer_Model\"\n",
    "model_save_path = os.path.join(base_model_path, model_name)\n",
    "\n",
    "# train(train_X, train_Y, training_batch_size, no_of_epochs, train_step_ranik, model_save_path, model_name, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Models/IDEA_2/RanikOptimizer_Model\n"
     ]
    }
   ],
   "source": [
    "# restore model and obtain the training and test accuracy:\n",
    "model_name = \"RanikOptimizer_Model\"\n",
    "model_save_path = os.path.join(base_model_path, model_name)\n",
    "\n",
    "print(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../../Models/IDEA_2/RanikOptimizer_Model/RanikOptimizer_Model-12\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(max_to_keep=3)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(model_save_path))\n",
    "    \n",
    "    # calculate predictions on the training dataset\n",
    "    preds_train = sess.run(predictions, feed_dict={tf_input_images: train_X})\n",
    "    \n",
    "    # calculate the predictions on the dev dataset\n",
    "    preds_dev = sess.run(predictions, feed_dict={tf_input_images: dev_X})\n",
    "    \n",
    "    # calculate the predictions on the test dataset\n",
    "    preds_test = sess.run(predictions, feed_dict={tf_input_images: test_X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train_set_accuracy = 97.9963636364\n",
      "Dev_set_accuracy = 96.42\n",
      "Test_set_accuracy = 96.21\n"
     ]
    }
   ],
   "source": [
    "# calculate the dev accuracy:\n",
    "train_accuracy = (np.sum((np.argmax(preds_train, axis=-1) == np.argmax(train_Y, axis=-1)).astype(np.float32)) / len(preds_train)) * 100\n",
    "print(\"Train_set_accuracy =\", train_accuracy)\n",
    "\n",
    "# calculate the dev accuracy:\n",
    "dev_accuracy = (np.sum((np.argmax(preds_dev, axis=-1) == np.argmax(dev_Y, axis=-1)).astype(np.float32)) / len(preds_dev)) * 100\n",
    "print(\"Dev_set_accuracy =\", dev_accuracy)\n",
    "\n",
    "# calculate the dev accuracy:\n",
    "test_accuracy = (np.sum((np.argmax(preds_test, axis=-1) == np.argmax(test_Y, axis=-1)).astype(np.float32)) / len(preds_test)) * 100\n",
    "print(\"Test_set_accuracy =\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../Models/IDEA_2/Adam_Model\n",
      "INFO:tensorflow:Restoring parameters from ../../Models/IDEA_2/Adam_Model/Adam_Model-12\n",
      "Train_set_accuracy = 99.6690909091\n",
      "Dev_set_accuracy = 98.2\n",
      "Test_set_accuracy = 97.82\n"
     ]
    }
   ],
   "source": [
    "# restore model and obtain the training and test accuracy:\n",
    "model_name = \"Adam_Model\"\n",
    "model_save_path = os.path.join(base_model_path, model_name)\n",
    "\n",
    "print(model_save_path)\n",
    "\n",
    "saver = tf.train.Saver(max_to_keep=3)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint(model_save_path))\n",
    "    \n",
    "    # calculate predictions on the training dataset\n",
    "    preds_train = sess.run(predictions, feed_dict={tf_input_images: train_X})\n",
    "    \n",
    "    # calculate the predictions on the dev dataset\n",
    "    preds_dev = sess.run(predictions, feed_dict={tf_input_images: dev_X})\n",
    "    \n",
    "    # calculate the predictions on the test dataset\n",
    "    preds_test = sess.run(predictions, feed_dict={tf_input_images: test_X})\n",
    "    \n",
    "\n",
    "    \n",
    "# calculate the dev accuracy:\n",
    "train_accuracy = (np.sum((np.argmax(preds_train, axis=-1) == np.argmax(train_Y, axis=-1)).astype(np.float32)) / len(preds_train)) * 100\n",
    "print(\"Train_set_accuracy =\", train_accuracy)\n",
    "\n",
    "# calculate the dev accuracy:\n",
    "dev_accuracy = (np.sum((np.argmax(preds_dev, axis=-1) == np.argmax(dev_Y, axis=-1)).astype(np.float32)) / len(preds_dev)) * 100\n",
    "print(\"Dev_set_accuracy =\", dev_accuracy)\n",
    "\n",
    "# calculate the dev accuracy:\n",
    "test_accuracy = (np.sum((np.argmax(preds_test, axis=-1) == np.argmax(test_Y, axis=-1)).astype(np.float32)) / len(preds_test)) * 100\n",
    "print(\"Test_set_accuracy =\", test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
