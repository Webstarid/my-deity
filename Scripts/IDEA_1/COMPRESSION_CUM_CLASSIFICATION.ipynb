{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is my first idea for going towards the hybrid architecture that I am looking to achieve. So, according to this idea, I am going to check if it works on the MNITS dataset or not.\n",
    "-------------------------------------------------------------------------------------------------------------------\n",
    "# Technology used: Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I start with the usual utility cells for this task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# packages used for machine learning\n",
    "import tensorflow as tf\n",
    "\n",
    "# packages used for processing: \n",
    "import matplotlib.pyplot as plt # for visualization\n",
    "import numpy as np\n",
    "\n",
    "# for operating system related stuff\n",
    "import os\n",
    "import sys # for memory usage of objects\n",
    "from subprocess import check_output\n",
    "\n",
    "# import pandas for reading the csv files\n",
    "import pandas as pd\n",
    "\n",
    "# to plot the images inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input data files are available in the \"../Data/\" directory.\n",
    "\n",
    "def exec_command(cmd):\n",
    "    '''\n",
    "        function to execute a shell command and see it's \n",
    "        output in the python console\n",
    "        @params\n",
    "        cmd = the command to be executed along with the arguments\n",
    "              ex: ['ls', '../input']\n",
    "    '''\n",
    "    print(check_output(cmd).decode(\"utf8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data\n",
      "LICENSE\n",
      "Literature_survey\n",
      "Models\n",
      "README.md\n",
      "Scripts\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the structure of the project directory\n",
    "exec_command(['ls', '../..'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Set the constants for the script '''\n",
    "\n",
    "# various paths of the files\n",
    "data_path = \"../../Data\" # the data path\n",
    "\n",
    "dataset = \"MNIST\"\n",
    "\n",
    "data_files = {\n",
    "    'train': os.path.join(data_path, dataset, \"train.csv\"),\n",
    "    'test' : os.path.join(data_path, dataset, \"test.csv\")\n",
    "}\n",
    "\n",
    "base_model_path = '../../Models'\n",
    "\n",
    "current_model_path = os.path.join(base_model_path, \"IDEA_1\")\n",
    "\n",
    "model_path_name = os.path.join(current_model_path, \"Model5\")\n",
    "\n",
    "# constant values:\n",
    "highest_pixel_value = 255\n",
    "train_percentage = 95\n",
    "num_classes = 10\n",
    "no_of_epochs = 500\n",
    "batch_size = 64\n",
    "hidden_neurons = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's load in the data:\n",
    "-------------------------------------------------------------------------------------------------------------------\n",
    "## and perform some basic preprocessing on it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv(data_files['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784 42000\n"
     ]
    }
   ],
   "source": [
    "n_features = len(raw_data.columns) - 1\n",
    "n_examples = len(raw_data.label)\n",
    "print n_features, n_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "5      0       0       0       0       0       0       0       0       0   \n",
       "6      7       0       0       0       0       0       0       0       0   \n",
       "7      3       0       0       0       0       0       0       0       0   \n",
       "8      5       0       0       0       0       0       0       0       0   \n",
       "9      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "5       0    ...            0         0         0         0         0   \n",
       "6       0    ...            0         0         0         0         0   \n",
       "7       0    ...            0         0         0         0         0   \n",
       "8       0    ...            0         0         0         0         0   \n",
       "9       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "5         0         0         0         0         0  \n",
       "6         0         0         0         0         0  \n",
       "7         0         0         0         0         0  \n",
       "8         0         0         0         0         0  \n",
       "9         0         0         0         0         0  \n",
       "\n",
       "[10 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = np.array(raw_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the data from the remaining raw_data\n",
    "features = np.ndarray((n_features, n_examples), dtype=np.float32)\n",
    "\n",
    "count = 0 # initialize from zero\n",
    "for pixel in raw_data.columns[1:]:\n",
    "    feature_slice = np.array(raw_data[pixel])\n",
    "    features[count, :] = feature_slice\n",
    "    count += 1 # increment count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(784, 42000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# normalize the pixel data by dividing the values by the highest_pixel_value\n",
    "features = features / highest_pixel_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fef54cffc90>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB4Ii/EBQhB8IivADQRF+ICjCDwT1f9QwYr9PSaNKAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fef550cca50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow((features[:, 9]).reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# use the function to generate the train_dev split\n",
    "-------------------------------------------------------------------------------------------------------------------\n",
    "link -> https://github.com/akanimax/machine-learning-helpers/blob/master/training/data_setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data using a random permutation\n",
    "perm = np.random.permutation(n_examples)\n",
    "features = features[:, perm]\n",
    "labels = labels[perm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fef54c000d0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEVCAYAAAAvoDOaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/h/z0dq+MgVEqgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fef54cb84d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_index = np.random.randint(n_examples)\n",
    "random_image = features[:, random_index].reshape((28, 28))\n",
    "# use plt to plot the image\n",
    "plt.figure().suptitle(\"Label of the image: \" + str(labels[random_index]))\n",
    "plt.imshow(random_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to split the data into train - dev sets:\n",
    "def split_train_dev(X, Y, train_percentage):\n",
    "    '''\n",
    "        function to split the given data into two small datasets (train - dev)\n",
    "        @param\n",
    "        X, Y => the data to be split\n",
    "        (** Make sure the train dimension is the first one)\n",
    "        train_percentage => the percentage which should be in the training set.\n",
    "        (**this should be in 100% not decimal)\n",
    "        @return => train_X, train_Y, test_X, test_Y\n",
    "    '''\n",
    "    m_examples = len(X)\n",
    "    assert train_percentage < 100, \"Train percentage cannot be greater than 100! NOOB!\"\n",
    "    partition_point = int((m_examples * (float(train_percentage) / 100)) + 0.5) # 0.5 is added for rounding\n",
    "\n",
    "    # construct the train_X, train_Y, test_X, test_Y sets:\n",
    "    train_X = X[: partition_point]; train_Y = Y[: partition_point]\n",
    "    test_X  = X[partition_point: ]; test_Y  = Y[partition_point: ]\n",
    "\n",
    "    assert len(train_X) + len(test_X) == m_examples, \"Something wrong in X splitting\"\n",
    "    assert len(train_Y) + len(test_Y) == m_examples, \"Something wrong in Y splitting\"\n",
    "\n",
    "    # return the constructed sets\n",
    "\n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X, test_Y = split_train_dev(features.T, labels, train_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39900, 784), (39900,), (2100, 784), (2100,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_Y.shape, test_X.shape, test_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((784, 39900), (784, 2100))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X = train_X.T; test_X = test_X.T\n",
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fef54b454d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEVCAYAAAAvoDOaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZoly+M0S9f/RoPSPLsTFyQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fef54c11490>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check by plotting some image\n",
    "random_index = np.random.randint(train_X.shape[-1])\n",
    "random_image = train_X[:, random_index].reshape((28, 28))\n",
    "# use plt to plot the image\n",
    "plt.figure().suptitle(\"Label of the image: \" + str(train_Y[random_index]))\n",
    "plt.imshow(random_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point to reset from here onwards: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# defining the Tensorflow graph for this task:\n",
    "tf.reset_default_graph() # reset the graph here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the placeholders:\n",
    "tf_input_pixels = tf.placeholder(tf.float32, shape=(n_features, None))\n",
    "tf_integer_labels = tf.placeholder(tf.int32, shape=(None,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image shaped pixels for the input_pixels:\n",
    "tf_input_images = tf.reshape(tf.transpose(tf_input_pixels), shape=(-1, 28, 28, 1))\n",
    "input_image_summary = tf.summary.image(\"input_image\", tf_input_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'one_hot:0' shape=(10, ?) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the one hot encoded version fo the integer_labels\n",
    "tf_one_hot_encoded_labels = tf.one_hot(tf_integer_labels, depth=num_classes, axis=0)\n",
    "tf_one_hot_encoded_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the variables for the layers:\n",
    "lay_0_b = tf.get_variable(\"layer_0_biases\", shape=(n_features, 1), \n",
    "                          dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "\n",
    "# layer 1 weights \n",
    "lay_1_W = tf.get_variable(\"layer_1_weights\", shape=(hidden_neurons, n_features), \n",
    "                              dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "lay_1_b = tf.get_variable(\"layer_1_biases\", shape=(hidden_neurons, 1), \n",
    "                            dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "\n",
    "# layer 2 weights\n",
    "lay_2_W = tf.get_variable(\"layer_2_weights\", shape=(hidden_neurons, hidden_neurons), \n",
    "                              dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "lay_2_b = tf.get_variable(\"layer_2_biases\", shape=(hidden_neurons, 1), \n",
    "                            dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "\n",
    "# layer 3 weights\n",
    "lay_3_W = tf.get_variable(\"layer_3_weights\", shape=(hidden_neurons, hidden_neurons), \n",
    "                              dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "lay_3_b = tf.get_variable(\"layer_3_biases\", shape=(hidden_neurons, 1), \n",
    "                            dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "\n",
    "# layer 4 weights\n",
    "lay_4_W = tf.get_variable(\"layer_4_weights\", shape=(hidden_neurons, hidden_neurons), \n",
    "                              dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "lay_4_b = tf.get_variable(\"layer_4_biases\", shape=(hidden_neurons, 1), \n",
    "                            dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "\n",
    "# layer 5 weights\n",
    "lay_5_W = tf.get_variable(\"layer_5_weights\", shape=(hidden_neurons, hidden_neurons), \n",
    "                              dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "lay_5_b = tf.get_variable(\"layer_5_biases\", shape=(hidden_neurons, 1), \n",
    "                            dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "\n",
    "# layer 6 weights\n",
    "lay_6_W = tf.get_variable(\"layer_6_weights\", shape=(hidden_neurons, hidden_neurons), \n",
    "                              dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "lay_6_b = tf.get_variable(\"layer_6_biases\", shape=(hidden_neurons, 1), \n",
    "                            dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "\n",
    "# layer 7 weights \n",
    "lay_7_W = tf.get_variable(\"layer_7_weights\", shape=(hidden_neurons, hidden_neurons), \n",
    "                              dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "lay_7_b = tf.get_variable(\"layer_7_biases\", shape=(hidden_neurons, 1), \n",
    "                            dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "\n",
    "# layer 2 weights\n",
    "lay_8_W = tf.get_variable(\"layer_8_weights\", shape=(hidden_neurons, hidden_neurons), \n",
    "                              dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "lay_8_b = tf.get_variable(\"layer_8_biases\", shape=(hidden_neurons, 1), \n",
    "                            dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "\n",
    "# layer 3 weights\n",
    "lay_9_W = tf.get_variable(\"layer_9_weights\", shape=(hidden_neurons, hidden_neurons), \n",
    "                              dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "lay_9_b = tf.get_variable(\"layer_9_biases\", shape=(hidden_neurons, 1), \n",
    "                            dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "\n",
    "# layer 4 weights\n",
    "lay_10_W = tf.get_variable(\"layer_10_weights\", shape=(hidden_neurons, hidden_neurons), \n",
    "                              dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "lay_10_b = tf.get_variable(\"layer_10_biases\", shape=(hidden_neurons, 1), \n",
    "                            dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "\n",
    "# layer 5 weights\n",
    "lay_11_W = tf.get_variable(\"layer_11_weights\", shape=(hidden_neurons, hidden_neurons), \n",
    "                              dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "lay_11_b = tf.get_variable(\"layer_11_biases\", shape=(hidden_neurons, 1), \n",
    "                            dtype=tf.float32, initializer=tf.zeros_initializer())\n",
    "\n",
    "# layer 6 weights\n",
    "lay_12_W = tf.get_variable(\"layer_12_weights\", shape=(num_classes, hidden_neurons), \n",
    "                              dtype=tf.float32, initializer=tf.contrib.layers.xavier_initializer())\n",
    "lay_12_b = tf.get_variable(\"layer_12_biases\", shape=(num_classes, 1), \n",
    "                            dtype=tf.float32, initializer=tf.zeros_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the forward computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward computation:\n",
    "z1 = tf.matmul(lay_1_W, tf_input_pixels) + lay_1_b\n",
    "a1 = tf.nn.relu(z1)\n",
    "\n",
    "z2 = tf.matmul(lay_2_W, a1) + lay_2_b\n",
    "a2 = tf.nn.relu(z2)\n",
    "\n",
    "z3 = tf.matmul(lay_3_W, a2) + lay_3_b\n",
    "a3 = tf.nn.relu(z3) \n",
    "\n",
    "z4 = tf.matmul(lay_4_W, a3) + lay_4_b\n",
    "a4 = tf.nn.relu(z4) \n",
    "\n",
    "z5 = tf.matmul(lay_5_W, a4) + lay_5_b\n",
    "a5 = tf.nn.relu(z5) \n",
    "\n",
    "z6 = tf.matmul(lay_6_W, a5) + lay_6_b\n",
    "a6 = tf.nn.relu(z6)\n",
    "\n",
    "z7 = tf.matmul(lay_7_W, a6) + lay_7_b\n",
    "a7 = tf.nn.relu(z7)\n",
    "\n",
    "z8 = tf.matmul(lay_8_W, a7) + lay_8_b\n",
    "a8 = tf.nn.relu(z8)\n",
    "\n",
    "z9 = tf.matmul(lay_9_W, a8) + lay_9_b\n",
    "a9 = tf.nn.relu(z9) \n",
    "\n",
    "z10 = tf.matmul(lay_10_W, a9) + lay_10_b\n",
    "a10 = tf.nn.relu(z10) \n",
    "\n",
    "z11 = tf.matmul(lay_11_W, a10) + lay_11_b\n",
    "a11 = tf.nn.relu(z11)\n",
    "\n",
    "z12 = tf.matmul(lay_12_W, a11) + lay_12_b\n",
    "a12 = tf.nn.relu(z12) # final activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define the backward computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the backward computations, there are no actiavtion functions\n",
    "y_in_back = a12\n",
    "\n",
    "a1_back = tf.abs(tf.matmul(tf.transpose(lay_12_W), y_in_back) + lay_11_b)\n",
    "a2_back = tf.abs(tf.matmul(tf.transpose(lay_11_W), a1_back) + lay_10_b)\n",
    "a3_back = tf.abs(tf.matmul(tf.transpose(lay_10_W), a2_back) + lay_9_b)\n",
    "a4_back = tf.abs(tf.matmul(tf.transpose(lay_9_W), a3_back) + lay_8_b)\n",
    "a5_back = tf.abs(tf.matmul(tf.transpose(lay_8_W), a4_back) + lay_7_b)\n",
    "a6_back = tf.abs(tf.matmul(tf.transpose(lay_7_W), a5_back) + lay_6_b)\n",
    "a7_back = tf.abs(tf.matmul(tf.transpose(lay_6_W), a6_back) + lay_5_b)\n",
    "a8_back = tf.abs(tf.matmul(tf.transpose(lay_5_W), a7_back) + lay_4_b)\n",
    "a9_back = tf.abs(tf.matmul(tf.transpose(lay_4_W), a8_back) + lay_3_b)\n",
    "a10_back = tf.abs(tf.matmul(tf.transpose(lay_3_W), a9_back) + lay_2_b)\n",
    "a11_back = tf.abs(tf.matmul(tf.transpose(lay_2_W), a10_back) + lay_1_b)\n",
    "a12_back = tf.abs(tf.matmul(tf.transpose(lay_1_W), a11_back) + lay_0_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor 'Abs_11:0' shape=(784, ?) dtype=float32>,\n",
       " <tf.Tensor 'Placeholder:0' shape=(784, ?) dtype=float32>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_out_back = a12_back\n",
    "x_out_back, tf_input_pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out_back_image = tf.reshape(tf.transpose(x_out_back), shape=(-1, 28, 28, 1))\n",
    "output_image_summary = tf.summary.image(\"output_image\", x_out_back_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now compute the forward cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward cost \n",
    "fwd_cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y_in_back, labels=tf_one_hot_encoded_labels))\n",
    "fwd_cost_summary = tf.summary.scalar(\"Forward_cost\", fwd_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now compute the backward cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# backward cost \n",
    "# The backward cost is the mean squared error function\n",
    "bwd_cost = tf.reduce_mean(tf.squared_difference(x_out_back, tf_input_pixels))\n",
    "bwd_cost_summary = tf.summary.scalar(\"Backward_cost\", bwd_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The final cost is the addition of both forward and the backward costs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = fwd_cost + bwd_cost\n",
    "final_cost_summary = tf.summary.scalar(\"Final_cost\", cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an optimizer for this task\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n",
    "init = tf.global_variables_initializer()\n",
    "all_summaries = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_train_examples = train_X.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "tensorboard_writer = tf.summary.FileWriter(model_path_name, graph=sess.graph, filename_suffix=\".bot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0 Cost: 26.7371\n",
      "Iteration: 100 Cost: 26.7084\n",
      "Iteration: 200 Cost: 26.6973\n",
      "Iteration: 300 Cost: 26.6894\n",
      "Iteration: 400 Cost: 166.376\n",
      "Iteration: 500 Cost: 9.07829e+10\n",
      "Iteration: 600 Cost: 4.3897e+07\n",
      "Average epoch cost: 27275825445.0\n",
      "Iteration: 624 Cost: 1.704e+07\n",
      "Iteration: 724 Cost: 1.49899e+06\n",
      "Iteration: 824 Cost: 215821.0\n",
      "Iteration: 924 Cost: 34630.9\n",
      "Iteration: 1024 Cost: 5584.44\n",
      "Iteration: 1124 Cost: 875.458\n",
      "Iteration: 1224 Cost: 147.454\n",
      "Average epoch cost: 1075608.7372\n",
      "Iteration: 1248 Cost: 101.532\n",
      "Iteration: 1348 Cost: 36.5088\n",
      "Iteration: 1448 Cost: 27.9523\n",
      "Iteration: 1548 Cost: 26.8686\n",
      "Iteration: 1648 Cost: 26.726\n",
      "Iteration: 1748 Cost: 26.7009\n",
      "Iteration: 1848 Cost: 26.6902\n",
      "Average epoch cost: 32.656726426\n",
      "Iteration: 1872 Cost: 26.6931\n",
      "Iteration: 1972 Cost: 26.6905\n",
      "Iteration: 2072 Cost: 26.6863\n",
      "Iteration: 2172 Cost: 26.6854\n",
      "Iteration: 2272 Cost: 26.6844\n",
      "Iteration: 2372 Cost: 26.6841\n",
      "Iteration: 2472 Cost: 26.681\n",
      "Average epoch cost: 26.6596201093\n",
      "Iteration: 2496 Cost: 26.6859\n",
      "Iteration: 2596 Cost: 26.6864\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-694afc0c1f46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# run the computation:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         _, loss = sess.run((optimizer, cost), feed_dict={tf_input_pixels: train_X_minibatch, \n\u001b[0;32m---> 14\u001b[0;31m                                                          tf_integer_labels: train_Y_minibatch})\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m# add the cost to the cost list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/animesh/Programming/platforms/anaconda3/envs/snakes/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/animesh/Programming/platforms/anaconda3/envs/snakes/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/animesh/Programming/platforms/anaconda3/envs/snakes/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/animesh/Programming/platforms/anaconda3/envs/snakes/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/animesh/Programming/platforms/anaconda3/envs/snakes/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# start training the network for num_iterations and using the batch_size\n",
    "global_step = 0\n",
    "for epoch in range(no_of_epochs):\n",
    "    global_index = 0; costs = [] # start with empty list\n",
    "    while(global_index < n_train_examples):\n",
    "        start = global_index; end = start + batch_size\n",
    "        train_X_minibatch = train_X[:, start: end]\n",
    "        train_Y_minibatch = train_Y.astype(np.int32)[start: end]\n",
    "\n",
    "        iteration = global_index / batch_size\n",
    "        \n",
    "        # run the computation:\n",
    "        _, loss = sess.run((optimizer, cost), feed_dict={tf_input_pixels: train_X_minibatch, \n",
    "                                                         tf_integer_labels: train_Y_minibatch})\n",
    "\n",
    "        # add the cost to the cost list\n",
    "        costs.append(loss)\n",
    "\n",
    "        if(iteration % 100 == 0):\n",
    "            sums = sess.run(all_summaries, feed_dict={tf_input_pixels: train_X_minibatch, \n",
    "                                                         tf_integer_labels: train_Y_minibatch})\n",
    "            \n",
    "            print \"Iteration: \" + str(global_step) + \" Cost: \" + str(loss)\n",
    "\n",
    "            tensorboard_writer.add_summary(sums, global_step = global_step)\n",
    "        \n",
    "        # increment the global index \n",
    "        global_index = global_index + batch_size\n",
    "    \n",
    "        global_step += 1\n",
    "        \n",
    "    # print the average epoch cost:\n",
    "    print \"Average epoch cost: \" + str(sum(costs) / len(costs))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
